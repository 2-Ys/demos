{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing Open LLMs with the OpenAI API\n",
    "This Notebook uses the same basic OpenAI Python API to run different local and serverless models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai langchain langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set model variables\n",
    "OPENAI_BASE_URL = \"https://api.openai.com/v1\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_ORGANIZATION = os.getenv(\"OPENAI_ORGANIZATION\")\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "OLLAMA_API_KEY = \"ollama\"\n",
    "\n",
    "TOGETHER_BASE_URL = \"https://api.together.xyz\"\n",
    "TOGETHER_API_KEY = os.getenv(\"TOGETHER_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize tools and models for all demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "MESSAGES = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that can access external functions. Please provide responses based on the information from these function calls.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the current temperature of New York, San Francisco and Chicago?\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a serverless Mixtral with the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": \"call_1kzlwrjs8ismtsvxjwylle7c\",\n",
      "    \"function\": {\n",
      "      \"arguments\": \"{\\\"location\\\":\\\"New York, NY\\\",\\\"format\\\":\\\"fahrenheit\\\"}\",\n",
      "      \"name\": \"get_current_weather\"\n",
      "    },\n",
      "    \"type\": \"function\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"call_odp89uvq3elogu1fjetwympy\",\n",
      "    \"function\": {\n",
      "      \"arguments\": \"{\\\"location\\\":\\\"San Francisco, CA\\\",\\\"format\\\":\\\"fahrenheit\\\"}\",\n",
      "      \"name\": \"get_current_weather\"\n",
      "    },\n",
      "    \"type\": \"function\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"call_32wezqk4yvdj8u7qvlsnu3qd\",\n",
      "    \"function\": {\n",
      "      \"arguments\": \"{\\\"location\\\":\\\"Chicago, IL\\\",\\\"format\\\":\\\"fahrenheit\\\"}\",\n",
      "      \"name\": \"get_current_weather\"\n",
      "    },\n",
      "    \"type\": \"function\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=TOGETHER_BASE_URL,\n",
    "    api_key=TOGETHER_API_KEY,\n",
    ")\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    messages=MESSAGES,\n",
    "    tools=TOOLS,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "print(json.dumps(response.choices[0].message.model_dump()[\"tool_calls\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can even stream responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\n",
      "  {\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"arguments\": {\n",
      "      \"location\": \"New York, NY\",\n",
      "      \"format\": \"fahrenheit\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"arguments\": {\n",
      "      \"location\": \"San Francisco, CA\",\n",
      "      \"format\": \"fahrenheit\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"arguments\": {\n",
      "      \"location\": \"Chicago, IL\",\n",
      "      \"format\": \"fahrenheit\"\n",
      "    }\n",
      "  }\n",
      "]"
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    messages=MESSAGES,\n",
    "    stream=True,\n",
    "    tools=TOOLS,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 5 different models with the same API: 2 Serverless, 2 Local, 1 OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIGS = [\n",
    "    {\n",
    "        \"description\": \"Llama2 Locally\",\n",
    "        \"base_url\": OLLAMA_BASE_URL,\n",
    "        \"api_key\": OLLAMA_API_KEY,\n",
    "        \"model\": \"llama2\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Mistral Locally\",\n",
    "        \"base_url\": OLLAMA_BASE_URL,\n",
    "        \"api_key\": OLLAMA_API_KEY,\n",
    "        \"model\": \"mistral\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Llama2 Serverless\",\n",
    "        \"base_url\": TOGETHER_BASE_URL,\n",
    "        \"api_key\": TOGETHER_API_KEY,\n",
    "        \"model\": \"togethercomputer/llama-2-13b-chat\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Mixtral Serverless\",\n",
    "        \"base_url\": TOGETHER_BASE_URL,\n",
    "        \"api_key\": TOGETHER_API_KEY,\n",
    "        \"model\": \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"OpenAI Serverless\",\n",
    "        \"base_url\": OPENAI_BASE_URL,\n",
    "        \"api_key\": OPENAI_API_KEY,\n",
    "        \"model\": \"gpt-3.5-turbo-1106\",\n",
    "    },\n",
    "]\n",
    "\n",
    "MESSAGES_FOR_POEMS = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a poet who writes whimsical haikus about a given topic.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Topic: Ducks\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Llama2 Locally:\n",
      "-----------------------------\n",
      "\n",
      "Quack quack in the pond,\n",
      "Feathers bright as sunflowers,\n",
      "Ducks dance on the water.\n",
      "\n",
      "Soft downy feathers,\n",
      "Glisten like silk in the sun,\n",
      "Ducklings play near.\n",
      "\n",
      "Rubber duck in bathtub,\n",
      "Squeaky cheeks and beady eyes,\n",
      "Relaxation found.\n",
      "\n",
      "Paddle boats on the lake,\n",
      "Ducks glide with graceful ease,\n",
      "Summer's sweet delight.\n",
      "\n",
      "\n",
      "Running Mistral Locally:\n",
      "-----------------------------\n",
      "\n",
      " Quiet pond stirs,\n",
      "\n",
      "Ducks dance, ripples mirror grace,\n",
      "Nature's ballet unfolds.\n",
      "\n",
      "Morning sun illumes,\n",
      "Golden reflection graces drake,\n",
      "In tranquil watery world.\n",
      "\n",
      "Autumn leaves fall gentle,\n",
      "Ducklings huddle close in line,\n",
      "Beneath the fiery sky.\n",
      "\n",
      "Through crystal glass I see,\n",
      "Silly ducks play tag and swim,\n",
      "Joyous underwater glee.\n",
      "\n",
      "In twilight's soft embrace,\n",
      "Mother duck guides her little ones,\n",
      "A sacred evening song.\n",
      "\n",
      "\n",
      "Running Llama2 Serverless:\n",
      "-----------------------------\n",
      "\n",
      " Quacking in the pond,\n",
      "Feathers fluffed and shining bright,\n",
      "Ducks dance in the sun.\n",
      "\n",
      "\n",
      "Running Mixtral Serverless:\n",
      "-----------------------------\n",
      "\n",
      "Feathers, bright and dappled,\n",
      "Water's surface, gently broken,\n",
      "Ducks, a dance of joy.\n",
      "\n",
      "In the pond, they play,\n",
      "Quacking tales of wind and rain,\n",
      "Ducks, in rhythm, sway.\n",
      "\n",
      "Sunset's glow, so soft,\n",
      "Ducks, in twilight, tuck away,\n",
      "Dreams of flight take hold.\n",
      "\n",
      "\n",
      "Running OpenAI Serverless:\n",
      "-----------------------------\n",
      "\n",
      "Feathers afloat, dance\n",
      "Amid ripples, quacks resound\n",
      "Ducklings waddle, play\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in MODEL_CONFIGS:\n",
    "\n",
    "    print(f\"Running {model['description']}:\")\n",
    "    print(f\"-----------------------------\\n\")\n",
    "\n",
    "    client = OpenAI(\n",
    "        base_url=model[\"base_url\"],\n",
    "        api_key=model[\"api_key\"],\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model[\"model\"],\n",
    "        messages=MESSAGES_FOR_POEMS,\n",
    "    )\n",
    "\n",
    "    print(f\"{response.choices[0].message.content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This also works well with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Llama2 Locally:\n",
      "-----------------------------\n",
      "\n",
      "\n",
      "Quackers in the pond,\n",
      "Feathered friends with webbed feet,\n",
      "Serenading me. \n",
      "\n",
      "\n",
      "Running Mistral Locally:\n",
      "-----------------------------\n",
      "\n",
      " Quiet pond stirs,\n",
      "Ducks dance in gentle ripple grace,\n",
      "Nature's joyous ballet.\n",
      "\n",
      "\n",
      "Running Llama2 Serverless:\n",
      "-----------------------------\n",
      "\n",
      " Here's a whimsical haiku about ducks:\n",
      "\n",
      "Quacky pals in a pond\n",
      "Feathered friends dance and splash\n",
      "Summer fun with flies.\n",
      "\n",
      "\n",
      "Running Mixtral Serverless:\n",
      "-----------------------------\n",
      "\n",
      "Quacking in glee,\n",
      "Feathers shimmering in sun,\n",
      "Dancing on the sea.\n",
      "\n",
      "\n",
      "Running OpenAI Serverless:\n",
      "-----------------------------\n",
      "\n",
      "Quacking in the pond\n",
      "Waddling in a merry line\n",
      "Ducks bring joy to all\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "for model in MODEL_CONFIGS:\n",
    "\n",
    "    print(f\"Running {model['description']}:\")\n",
    "    print(f\"-----------------------------\\n\")\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_base=model[\"base_url\"],\n",
    "        api_key=model[\"api_key\"],\n",
    "        model=model[\"model\"],\n",
    "        temperature=1.0,\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"Write a whimsical haiku about a given topic.\"),\n",
    "            (\"user\", \"Topic: Ducks\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    poem_runnable = prompt | llm\n",
    "\n",
    "    response = poem_runnable.invoke({})\n",
    "    print(f\"{response.content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
